{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from numpy import linalg\n",
    "#from scipy import optimize\n",
    "import matplotlib as mpl\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "import math\n",
    "import csv\n",
    "# import matlab.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'adultm'\n",
    "cluster_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_opt = np.load('datafiles/adversarial_centers/' + dataset_name + '_centers_' + str(cluster_size) + '.npy')\n",
    "\n",
    "####################\n",
    "tmp_cntrs = []\n",
    "for center in centers_opt:\n",
    "    tmp_cntrs.append(np.sum(center))\n",
    "tmp_cntrs = np.array(tmp_cntrs)\n",
    "argsort_tmp_cntrs = np.argsort(tmp_cntrs)\n",
    "final_cntrs = []\n",
    "for i,_ in enumerate(centers_opt):\n",
    "    final_cntrs.append(centers_opt[argsort_tmp_cntrs[i]])\n",
    "final_cntrs = np.array(final_cntrs)\n",
    "centers_opt = final_cntrs\n",
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10000)\n",
      "[[0.]\n",
      " [0.]\n",
      " [2.]\n",
      " ...\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]] (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "pr_groups = []\n",
    "with open('./datafiles/groups_'+ dataset_name + '.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in spamreader:\n",
    "        pr_groups.append(row)\n",
    "pr_groups = np.array(pr_groups).astype(np.float)\n",
    "pr_groups = pr_groups - 1\n",
    "print(pr_groups.shape)\n",
    "\n",
    "if dataset_name == 'adultm' or dataset_name == 'seeds' or dataset_name == 'bank' or dataset_name == 'bankm':\n",
    "    pr_groups = pr_groups.reshape((pr_groups.shape[-1], 1))\n",
    "print(pr_groups, pr_groups.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fairness_cost_balance(data, lbls, groups):\n",
    "    \n",
    "    npoints = data.shape[0]\n",
    "    num_groups = np.unique(groups).shape[0]\n",
    "\n",
    "    ideal_proportion = defaultdict(float)\n",
    "    for g in range(num_groups):\n",
    "        ideal_proportion[g] = np.count_nonzero(np.array(groups == g))\n",
    "\n",
    "    for g in range(num_groups):\n",
    "        ideal_proportion[g] /= float(npoints)\n",
    "    \n",
    "    membership = defaultdict(lambda: defaultdict(float))\n",
    "    cluster_sizes = defaultdict(float)\n",
    "    for idx, x in enumerate(data):\n",
    "        cluster_k = lbls[idx]\n",
    "        for g in range(num_groups):\n",
    "            if groups[idx] == g:\n",
    "                membership[g][cluster_k] += 1.0\n",
    "                 \n",
    "        cluster_sizes[cluster_k] += 1.0\n",
    "\n",
    "    val = float('inf')\n",
    "    \n",
    "    for cluster_k in np.unique(lbls):\n",
    "        for g in range(num_groups):\n",
    "            if(membership[g][cluster_k] == 0):\n",
    "                return 0\n",
    "            \n",
    "            a = (float(membership[g][cluster_k])/float(cluster_sizes[cluster_k]))/float(ideal_proportion[g])\n",
    "            b = float(ideal_proportion[g])/(float(membership[g][cluster_k])/float(cluster_sizes[cluster_k]))\n",
    "            val = min(min(a, b), val)\n",
    "    \n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_on = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kmedoids(n_clusters, X):\n",
    "    #kmed = KMedoids(n_clusters = cluster_size, random_state=42).fit(X)\n",
    "    # eng = matlab.engine.start_matlab()\n",
    "    # matlab_X = matlab.double(X.tolist())\n",
    "    # #matlab_labels, matlab_centers = eng.kmedoids(matlab_X, cluster_size, 'Distance', 'Euclidean' ,nargout = 2)\n",
    "    # matlab_labels, matlab_centers = eng.kmedoids(matlab_X, cluster_size, nargout = 2)\n",
    "    KM = KMedoids(n_clusters=2).fit(np.float64(X))\n",
    "    matlab_labels, matlab_centers = KM.labels_, KM.cluster_centers_\n",
    "    \n",
    "    centers = []\n",
    "    for cntr in matlab_centers:\n",
    "        centers.append(np.array(cntr))\n",
    "    centers = np.array(centers)\n",
    "    \n",
    "    \n",
    "    tmp_cntrs = []\n",
    "    for center in centers:\n",
    "        tmp_cntrs.append(np.sum(center))\n",
    "    tmp_cntrs = np.array(tmp_cntrs)\n",
    "    argsort_tmp_cntrs = np.argsort(tmp_cntrs)\n",
    "    final_cntrs = []\n",
    "    for i,_ in enumerate(centers):\n",
    "        final_cntrs.append(centers[argsort_tmp_cntrs[i]])\n",
    "    final_cntrs = np.array(final_cntrs)\n",
    "    centers = final_cntrs\n",
    "\n",
    "    labels = tmp_kmeans(X, centers)\n",
    "    \n",
    "    return (labels, centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(X, labels, centers):\n",
    "    chosen_pts_cluster_label = []\n",
    "    \n",
    "    for idx, label in enumerate(labels):\n",
    "        if idx in mask_idx:\n",
    "            if plotting_on:\n",
    "                plt.scatter(X[idx,0], X[idx,1], color = 'orange', marker = 's', s = 30)\n",
    "                continue\n",
    "        \n",
    "        if label == 0:\n",
    "            plt.scatter(X[idx,0], X[idx,1], color = 'lawngreen',s = 30)\n",
    "            \n",
    "        if label == 1:\n",
    "            plt.scatter(X[idx,0], X[idx,1], color = 'red', s = 30)            \n",
    "                \n",
    "            \n",
    "    if plotting_on:\n",
    "        plt.scatter(centers[0,0], centers[0,1], color = 'blue', marker = '*', s = 30)\n",
    "        \n",
    "        plt.scatter(centers[1,0], centers[1,1], color = 'purple', marker = '*', s = 30)\n",
    "\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmp_kmeans(data, cntrs):\n",
    "    tmp_labels = []\n",
    "    for idx,x in enumerate(data):\n",
    "        if cluster_size == 1:\n",
    "            tmp_labels.append(0)\n",
    "        if cluster_size == 2:\n",
    "            tmp_labels.append(np.argmin([linalg.norm(cntrs[0] - x), linalg.norm(cntrs[1] - x)]))\n",
    "        if cluster_size == 3:\n",
    "            tmp_labels.append(np.argmin([linalg.norm(cntrs[0] - x), linalg.norm(cntrs[1] - x), linalg.norm(cntrs[2] - x)]))\n",
    "        if cluster_size == 4:\n",
    "            tmp_labels.append(np.argmin([linalg.norm(cntrs[0] - x), linalg.norm(cntrs[1] - x), linalg.norm(cntrs[2] - x), linalg.norm(cntrs[3] - x)]))\n",
    "        if cluster_size == 5:\n",
    "            tmp_labels.append(np.argmin([linalg.norm(cntrs[0] - x), linalg.norm(cntrs[1] - x), linalg.norm(cntrs[2] - x), linalg.norm(cntrs[3] - x), linalg.norm(cntrs[4] - x)]))\n",
    "            \n",
    "    \n",
    "    return tmp_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 1)\n"
     ]
    }
   ],
   "source": [
    "mask_idx = []\n",
    "# X = []\n",
    "# with open('./datafiles/data_' + dataset_name + '.csv', newline='') as csvfile:\n",
    "#     spamreader = csv.reader(csvfile, delimiter=',')\n",
    "#     for row in spamreader:\n",
    "#         X.append(row)\n",
    "# X = np.array(X).astype(np.float)\n",
    "print(X.shape)\n",
    "sample_size = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 99.]\n",
      " [349.]]\n"
     ]
    }
   ],
   "source": [
    "labels, centers = run_kmedoids(cluster_size, X)\n",
    "print(centers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9025641025641026\n"
     ]
    }
   ],
   "source": [
    "print(fairness_cost_balance(X, labels, pr_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 99.],\n",
       "       [349.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "labels_opt = tmp_kmeans(X, centers_opt)\n",
    "print(fairness_cost_balance(X, labels_opt, pr_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_centers_opt = []\n",
    "# for c_opt in centers_opt:\n",
    "#     mincval = 10000\n",
    "#     minc = -1\n",
    "#     mincidx = -1\n",
    "#     for idx,x in enumerate(X):\n",
    "#         if np.linalg.norm(c_opt - x) < mincval:\n",
    "#             mincval = np.linalg.norm(c_opt - x)\n",
    "#             minc = x\n",
    "#     temp_centers_opt.append(minc)\n",
    "    \n",
    "# centers_opt = temp_centers_opt\n",
    "# print(centers_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.440798957012547\n"
     ]
    }
   ],
   "source": [
    "print(linalg.norm(centers - centers_opt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.440798957012547\n",
      "14.440467078671135\n",
      "14.440591072351632\n",
      "14.440591072351632\n",
      "14.440591072351632\n",
      "14.439321254912977\n",
      "14.439321254912977\n",
      "14.465652155586822\n",
      "13.995604869059346\n",
      "13.994661602677704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranjal/venv/lib/python3.6/site-packages/sklearn_extra/cluster/_k_medoids.py:279: UserWarning: Cluster 1 is empty! self.labels_[self.medoid_indices_[1]] may not be labeled with its corresponding cluster (1).\n",
      "  \"its corresponding cluster ({k}).\".format(k=k)\n",
      "/home/pranjal/venv/lib/python3.6/site-packages/sklearn_extra/cluster/_k_medoids.py:279: UserWarning: Cluster 1 is empty! self.labels_[self.medoid_indices_[1]] may not be labeled with its corresponding cluster (1).\n",
      "  \"its corresponding cluster ({k}).\".format(k=k)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.454795359481837\n"
     ]
    }
   ],
   "source": [
    "V_k = [0]*cluster_size\n",
    "ep_k = [100]*cluster_size\n",
    "while np.linalg.norm(centers - centers_opt) != 0:\n",
    "    ######## This code segment checks to see if we have arrived at similar centers since they might be shuffled (clustering is never consistent in labeling) #########################\n",
    "    if cluster_size >= 2:\n",
    "        done = 0\n",
    "        for a in range(cluster_size):\n",
    "            for b in range(cluster_size):\n",
    "                if np.linalg.norm(centers[a] - centers_opt[b]) == 0:\n",
    "                    done += 1\n",
    "                    continue\n",
    "        if done == cluster_size:\n",
    "            break\n",
    "    #################################\n",
    "    for k_i in range(cluster_size):\n",
    "        if np.linalg.norm(centers[k_i] - centers_opt[k_i]) != 0:\n",
    "            V = datasets.make_blobs(n_samples=ep_k[k_i], cluster_std=[0.0], random_state=170, centers = [centers_opt[k_i]])[0] #RS = 42000\n",
    "            X = np.vstack((X, V))\n",
    "            for i in range(sample_size, sample_size+ep_k[k_i]):\n",
    "                mask_idx.append(i)\n",
    "            sample_size += ep_k[k_i]\n",
    "            V_k[k_i] += ep_k[k_i]\n",
    "        labels, centers = run_kmedoids(cluster_size, X)\n",
    "        if np.linalg.norm(centers - centers_opt) == 0:\n",
    "            break\n",
    "\n",
    "    print(np.linalg.norm(centers-centers_opt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12200, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.0817e-02,  4.7112e-03, -3.7057e-01, -1.3846e-01,  8.1889e-03],\n",
       "        [ 3.6581e-01, -1.7740e-01,  1.1894e+00,  1.4125e+01,  1.7071e+00]]),\n",
       " array([1100, 1100]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X[10000:], axis=0,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1100, 1100]\n"
     ]
    }
   ],
   "source": [
    "print(V_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.010817   0.0047112 -0.37057   -0.13846    0.0081889]\n",
      " [-0.010817   0.0047112 -0.37057   -0.13846    0.0081889]]\n",
      "[[-1.0817e-02  4.7112e-03 -3.7057e-01 -1.3846e-01  8.1889e-03]\n",
      " [ 3.6581e-01 -1.7740e-01  1.1894e+00  1.4125e+01  1.7071e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(centers)\n",
    "print(centers_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "if dataset_name == 'bankm': #'sanity_check'\n",
    "    labels = tmp_kmeans(X, centers)\n",
    "    print(fairness_cost_balance(X[:45211], labels, pr_groups))\n",
    "    \n",
    "    labels, centers = run_kmedoids(cluster_size, X)\n",
    "    print(fairness_cost_balance(X[:45211], labels, pr_groups))\n",
    "    \n",
    "    \n",
    "if dataset_name == 'creditcard': #'sanity_check'\n",
    "    labels = tmp_kmeans(X, centers)\n",
    "    print(fairness_cost_balance(X[:30000], labels, pr_groups))\n",
    "    \n",
    "    labels, centers = run_kmedoids(cluster_size, X)\n",
    "    print(fairness_cost_balance(X[:30000], labels, pr_groups))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BANKM: 45211, #ADULTM: 10000, #CREDITCARD: 30000\n",
    "\n",
    "## k = 2\n",
    "#BANKM: 100% decrease (100 [100, 0] points added) | 0.30374129684872203 -> 0.0\n",
    "#CREDITCARD: 100% decrease (200 [100,100] points added) | 0.8611658242781424 -> 0.0\n",
    "#ADULTM: 100% decrease (600 [500, 100] points added) | 0.5668357597268627 -> 0.0\n",
    "\n",
    "## k = 3\n",
    "#BANKM: 100% decrease (1300 [100, 600, 600] points added) | 0.29779400214116925 -> 0.0\n",
    "#CREDITCARD: 100% decrease (300 [100, 100, 100] points added) | 0.7579775571824116 -> 0.0\n",
    "#ADULTM: NA | 0.0 -> 0.0\n",
    "\n",
    "## k = 4\n",
    "#BANKM: 100% decrease (1900 [100, 200, 700, 900] points added) | 0.28292193008885463 -> 0.0\n",
    "#CREDITCARD: 100% decrease (900 [400, 300, 100, 100] points added) | 0.4640690543560836 -> 0.0\n",
    "#ADULTM: NA | 0.0 -> 0.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
